{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb54ae9a-94e7-4b39-bf6b-c8b5f13c6778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T14:44:56.403533Z",
     "iopub.status.busy": "2024-06-15T14:44:56.402614Z",
     "iopub.status.idle": "2024-06-15T14:44:56.423313Z",
     "shell.execute_reply": "2024-06-15T14:44:56.422600Z",
     "shell.execute_reply.started": "2024-06-15T14:44:56.403477Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cb7812f-e457-4251-a060-20d606055554",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T12:36:18.538735Z",
     "iopub.status.busy": "2024-06-15T12:36:18.537457Z",
     "iopub.status.idle": "2024-06-15T12:36:18.552791Z",
     "shell.execute_reply": "2024-06-15T12:36:18.551993Z",
     "shell.execute_reply.started": "2024-06-15T12:36:18.538682Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_class_names(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        class_names = [line.strip() for line in file.readlines()]\n",
    "    return class_names\n",
    "\n",
    "def load_image(image_path):\n",
    "    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def load_labels(label_path):\n",
    "    with open(label_path, 'r') as file:\n",
    "        labels = [line.strip().split() for line in file.readlines()]\n",
    "    return labels\n",
    "\n",
    "def plot_image_with_labels(image, labels, class_names, image_id):\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'Image ID: {image_id}')\n",
    "    height, width, _ = image.shape\n",
    "    for label in labels:\n",
    "        class_id, x_center, y_center, bbox_width, bbox_height = map(float, label)\n",
    "        x_center *= width\n",
    "        y_center *= height\n",
    "        bbox_width *= width\n",
    "        bbox_height *= height\n",
    "        x_min = x_center - bbox_width / 2\n",
    "        y_min = y_center - bbox_height / 2\n",
    "        rect = plt.Rectangle((x_min, y_min), bbox_width, bbox_height, edgecolor='r', facecolor='none')\n",
    "        plt.gca().add_patch(rect)\n",
    "        \n",
    "        # Добавление текста с именем класса\n",
    "        class_name = class_names[int(class_id)]\n",
    "        # plt.text(x_min, y_min - 10, class_name, color='red', fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec2f9532-4417-4490-8ebc-f7fbc33d6342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T09:47:19.483445Z",
     "iopub.status.busy": "2024-06-15T09:47:19.481946Z",
     "iopub.status.idle": "2024-06-15T09:47:19.499810Z",
     "shell.execute_reply": "2024-06-15T09:47:19.498760Z",
     "shell.execute_reply.started": "2024-06-15T09:47:19.483388Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inferance(yolo, image_path, label_path):\n",
    "    img = load_image(image_path)\n",
    "    labels = load_labels(label_path)\n",
    "    pred = yolo(img, conf=0.5, device='cuda', show=False, save=True)\n",
    "    pred_boxes = pred[0].boxes.xywhn.cpu().numpy() \n",
    "    pred_cls = pred[0].boxes.cls.cpu().numpy().reshape(-1, 1)\n",
    "    pred_labels = np.hstack([pred_cls, pred_boxes])\n",
    "    \n",
    "    plot_image_with_labels(img, labels, pred_boxes, image_id='True')\n",
    "    plot_image_with_labels(img, pred_labels, pred_boxes, image_id='Predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e10eae2c-bd0f-431e-800f-f54a38a27aad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T12:36:33.232458Z",
     "iopub.status.busy": "2024-06-15T12:36:33.231266Z",
     "iopub.status.idle": "2024-06-15T12:36:33.244720Z",
     "shell.execute_reply": "2024-06-15T12:36:33.243846Z",
     "shell.execute_reply.started": "2024-06-15T12:36:33.232413Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_path = '/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/val/images/1 (11).jpg'\n",
    "label_path = '/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/val/labels/1 (11).txt'\n",
    "\n",
    "# inferance(yolo, image_path, label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3212e88f-1510-475a-9b69-45e728996f3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T12:37:44.948849Z",
     "iopub.status.busy": "2024-06-15T12:37:44.947589Z",
     "iopub.status.idle": "2024-06-15T12:37:44.973763Z",
     "shell.execute_reply": "2024-06-15T12:37:44.972961Z",
     "shell.execute_reply.started": "2024-06-15T12:37:44.948801Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2'], dtype='<U8')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array(load_labels('/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/test/labels/9 (73).txt'))[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6e5e0d48-f237-47fe-b140-89eb1e2dfae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T16:14:44.433837Z",
     "iopub.status.busy": "2024-06-15T16:14:44.432448Z",
     "iopub.status.idle": "2024-06-15T16:14:44.450124Z",
     "shell.execute_reply": "2024-06-15T16:14:44.449387Z",
     "shell.execute_reply.started": "2024-06-15T16:14:44.433778Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "\n",
    "def load_labels(label_path):\n",
    "    with open(label_path, 'r') as file:\n",
    "        labels = [line.strip().split() for line in file.readlines()]\n",
    "    return np.array(labels)\n",
    "\n",
    "class CustomData(Dataset):\n",
    "    def __init__(self, image_dir, bbox_dir, img_size, labels_dict, transform=None):\n",
    "        super(CustomData).__init__()\n",
    "        self.image_dir = image_dir\n",
    "        self.bbox_dir = bbox_dir\n",
    "        self.img_size = img_size\n",
    "        self.labels_dict = labels_dict\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(self.image_dir)\n",
    "        self.bboxes = os.listdir(self.bbox_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bbox_dir)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.images[index]\n",
    "        bbox_name = self.bboxes[index]\n",
    "        image_path = rf'{self.image_dir}/{image_name}'\n",
    "        bbox_path = rf'{self.bbox_dir}/{bbox_name}'\n",
    "        print(image_path)\n",
    "        # image = cv2.imread(image_path)\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB), (640, 640))\n",
    "        labels_bboxes = load_labels(bbox_path)\n",
    "        print(labels_bboxes.shape)\n",
    "        if labels_bboxes is None:\n",
    "            return image, []\n",
    "\n",
    "        if len(labels_bboxes)==0:\n",
    "            return image, []\n",
    "\n",
    "        # print(labels_bboxes)\n",
    "        labels = labels_bboxes[:, 0].astype(np.int16)\n",
    "        bboxes = labels_bboxes[:, 1:].astype(np.float16)\n",
    "        w, h, _ = image.shape\n",
    "        \n",
    "        \n",
    "        # # shape=(1, 4)\n",
    "        # bboxes[:, 0] = bboxes[:, 0]*w\n",
    "        # bboxes[:, 2] = bboxes[:, 2]*w\n",
    "        # bboxes[:, 1] = bboxes[:, 1]*h\n",
    "        # bboxes[:, 3] = bboxes[:, 3]*h\n",
    "        \n",
    "\n",
    "        # bboxes = torch.tensor(bboxes, dtype=torch.int16)\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, bboxes=bboxes)\n",
    "            image = transformed['image']\n",
    "            bboxes = transformed['bboxes']\n",
    "        \n",
    "        \n",
    "        ########################################################\n",
    "\n",
    "        area = (bboxes[:, 3] - bboxes[:, 1]) * (bboxes[:, 2] - bboxes[:, 0])\n",
    "        area = torch.tensor(area, dtype=torch.int16)\n",
    "        # labels = [self.labels_dict[label] for label in bboxes[:, 4]]\n",
    "        labels = torch.tensor(labels, dtype=torch.int16)\n",
    "        \n",
    "        # labels = None\n",
    "        target = dict()\n",
    "        target['boxes'] = bboxes\n",
    "        target['labels'] = labels\n",
    "        target['image_id'] = torch.tensor([index], dtype=torch.int16)\n",
    "        target['area'] = area\n",
    "\n",
    "        ########################################################\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "baf02b3f-c970-494a-90b3-e278c4032ba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T16:24:06.000371Z",
     "iopub.status.busy": "2024-06-15T16:24:05.998986Z",
     "iopub.status.idle": "2024-06-15T16:24:06.011474Z",
     "shell.execute_reply": "2024-06-15T16:24:06.010647Z",
     "shell.execute_reply.started": "2024-06-15T16:24:06.000312Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_train_transforms():\n",
    "#     return A.Compose([\n",
    "#         A.Resize(640, 640),\n",
    "#         A.SomeOf([\n",
    "#             A.Blur(p=1, blur_limit=3),\n",
    "#             A.Flip(p=1, always_apply=True),\n",
    "#             A.GaussNoise(p=1, always_apply=True),\n",
    "#             A.GridDistortion(p=1, always_apply=True),\n",
    "#             A.Rotate((-45, 45), p=1, always_apply=True),\n",
    "#             A.Transpose(p=1, always_apply=True),\n",
    "#             A.RandomBrightnessContrast((-0.1, 0.1), (-0.1, 0.1), p=1, always_apply=True)\n",
    "#         ], p=0.9, n=1),\n",
    "#         ToTensorV2()\n",
    "#     ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "# class CustomData(Dataset):\n",
    "#     def __init__(self, image_dir, bbox_dir, img_size, labels_dict, transform=None):\n",
    "#         super(CustomData).__init__()\n",
    "#         self.image_dir = image_dir\n",
    "#         self.bbox_dir = bbox_dir\n",
    "#         self.img_size = img_size\n",
    "#         self.labels_dict = labels_dict\n",
    "#         self.transform = transform\n",
    "#         self.images = os.listdir(self.image_dir)\n",
    "#         self.bboxes = os.listdir(self.bbox_dir)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.bboxes)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         image_name = self.images[index]\n",
    "#         bbox_name = self.bboxes[index]\n",
    "#         image_path = os.path.join(self.image_dir, image_name)\n",
    "#         bbox_path = os.path.join(self.bbox_dir, bbox_name)\n",
    "#         image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "#         labels_bboxes = load_labels(bbox_path)\n",
    "\n",
    "#         if labels_bboxes is None or len(labels_bboxes) == 0:\n",
    "#             return image, []\n",
    "\n",
    "#         labels = labels_bboxes[:, 0].astype(np.int16)\n",
    "#         bboxes = labels_bboxes[:, 1:].astype(np.float32)\n",
    "\n",
    "#         if self.transform:\n",
    "#             transformed = self.transform(image=image, bboxes=bboxes, labels=labels)\n",
    "#             image = transformed['image']\n",
    "#             bboxes = transformed['bboxes']\n",
    "#             labels = transformed['labels']\n",
    "\n",
    "#         area = (bboxes[:, 3] - bboxes[:, 1]) * (bboxes[:, 2] - bboxes[:, 0])\n",
    "#         area = torch.tensor(area, dtype=torch.float32)\n",
    "#         labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "#         target = dict()\n",
    "#         target['boxes'] = torch.tensor(bboxes, dtype=torch.float32)\n",
    "#         target['labels'] = labels\n",
    "#         target['image_id'] = torch.tensor([index], dtype=torch.int64)\n",
    "#         target['area'] = area\n",
    "\n",
    "#         return image, target\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch = list(filter(lambda x: len(x[1]) > 0, batch))\n",
    "    if not batch:\n",
    "        return torch.empty(0), torch.empty(0)\n",
    "    images, targets = zip(*batch)\n",
    "    images = torch.stack(images)\n",
    "    return images, targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f5364b34-3589-4738-b258-141c0c7eeaff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T16:24:06.196438Z",
     "iopub.status.busy": "2024-06-15T16:24:06.195083Z",
     "iopub.status.idle": "2024-06-15T16:24:06.212037Z",
     "shell.execute_reply": "2024-06-15T16:24:06.211261Z",
     "shell.execute_reply.started": "2024-06-15T16:24:06.196393Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN_ResNet50_FPN_V2_Weights, FasterRCNN_MobileNet_V3_Large_FPN_Weights\n",
    "import torch\n",
    "\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def get_model(num_classes = 6): # 4 = 3 + 1, учитываем еще фон\n",
    "    # box_detections_per_img=50\n",
    "    model = fasterrcnn_resnet50_fpn_v2(weights=FasterRCNN_ResNet50_FPN_V2_Weights.COCO_V1)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes).to(DEVICE)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "903c4a30-8bb7-41db-a1fb-9662b7a915a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T16:24:06.697992Z",
     "iopub.status.busy": "2024-06-15T16:24:06.696809Z",
     "iopub.status.idle": "2024-06-15T16:24:06.727312Z",
     "shell.execute_reply": "2024-06-15T16:24:06.726456Z",
     "shell.execute_reply.started": "2024-06-15T16:24:06.697943Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import clearml\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "\n",
    "def train(train_loader, val_loader, epochs):\n",
    "    model = get_model(num_classes=6)\n",
    "    params = [param for param in model.parameters() if param.requires_grad]\n",
    "    optimizer = optim.SGD(params,  lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "    \n",
    "    total_train_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch: {epoch + 1}')\n",
    "        train_loss = []\n",
    "        model.train()\n",
    "        for images, targets in train_loader:\n",
    "            images = list(torch.tensor(image, dtype=torch.float32).to(device) for image in images)\n",
    "            targets = [{k: torch.tensor(v, dtype=torch.int32).to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            train_loss.append(losses.item())\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_train_loss = np.mean(train_loss)\n",
    "        total_train_loss.append(epoch_train_loss)\n",
    "        print(f'Epoch train loss is: {epoch_train_loss}')\n",
    "\n",
    "    return model, total_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8c7063b7-7784-4272-b5ea-ef1544a68ced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T16:24:06.951789Z",
     "iopub.status.busy": "2024-06-15T16:24:06.950817Z",
     "iopub.status.idle": "2024-06-15T16:24:06.963775Z",
     "shell.execute_reply": "2024-06-15T16:24:06.962952Z",
     "shell.execute_reply.started": "2024-06-15T16:24:06.951746Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "                A.SomeOf([\n",
    "                    A.Blur(p=1, blur_limit=3),\n",
    "                    A.Flip(p=1, ),\n",
    "                    A.GaussNoise(p=1),\n",
    "                    A.Transpose(p=1),\n",
    "                    \n",
    "                    # A.GridDistortion(p=1),\n",
    "                    # A.Rotate((-45, 45), p=1, ),\n",
    "                    # A.MedianBlur(p=1),\n",
    "                    # A.CLAHE(p=1),\n",
    "                    # A.RandomBrightnessContrast(p=1),\n",
    "                    # A.RandomGamma(p=1),\n",
    "                ], p=0.9, n=1),\n",
    "                A.Resize(640, 640),\n",
    "                A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "val_transform = A.Compose([\n",
    "        A.Resize(640, 640),\n",
    "        ToTensorV2()\n",
    "])\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "bae6e211-18c4-4702-b4f7-fbe2c9945cac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T16:24:07.208223Z",
     "iopub.status.busy": "2024-06-15T16:24:07.207038Z",
     "iopub.status.idle": "2024-06-15T16:24:07.225035Z",
     "shell.execute_reply": "2024-06-15T16:24:07.224303Z",
     "shell.execute_reply.started": "2024-06-15T16:24:07.208150Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# dataset = CustomData(image_dir, bbox_dir, img_size=640, labels_dict=labels_dict, transform=get_train_transforms())\n",
    "# dataloader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_dataset = CustomData(image_dir='/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images', \n",
    "                              bbox_dir='/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/labels',\n",
    "                              img_size=(640, 640), \n",
    "                              labels_dict='', \n",
    "                              transform=None)\n",
    "\n",
    "val_dataset = CustomData(image_dir='/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/val/images', \n",
    "                              bbox_dir='/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/val/labels',\n",
    "                              img_size=(640, 640), \n",
    "                              labels_dict='', \n",
    "                              transform=None)\n",
    "# test_dataset = CustomData(image_dir, bbox_dir, img_size, labels_dict, transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "21e39c32-a34f-44f2-8469-26089deb34f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T16:24:07.429180Z",
     "iopub.status.busy": "2024-06-15T16:24:07.428133Z",
     "iopub.status.idle": "2024-06-15T16:24:09.758462Z",
     "shell.execute_reply": "2024-06-15T16:24:09.756994Z",
     "shell.execute_reply.started": "2024-06-15T16:24:07.429136Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images/9 (26).jpg\n",
      "(1, 5)\n",
      "/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images/7 (19).jpg\n",
      "(12, 5)\n",
      "/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images/6 (20).jpg\n",
      "(1, 5)\n",
      "/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images/3 (41).jpg\n",
      "(0,)\n",
      "/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images/7 (156).jpg\n",
      "(9, 5)\n",
      "/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images/7 (220).jpg\n",
      "(4, 5)\n",
      "/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images/7 (196).jpg\n",
      "(1, 5)\n",
      "/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images/8 (78).jpg\n",
      "(4, 5)\n",
      "/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images/8 (66).jpg\n",
      "(3, 5)\n",
      "/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images/7 (222).jpg\n",
      "(1, 5)\n",
      "/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images/5 (28).jpg\n",
      "(5, 5)\n",
      "/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images/7 (208).jpg\n",
      "(3, 5)\n",
      "/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images/7 (41).jpg\n",
      "(10, 5)\n",
      "/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images/9 (13).jpg\n",
      "(4, 5)\n",
      "/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images/4 (11).jpg\n",
      "(1, 5)\n",
      "/home/jupyter/datasphere/project/atomic_hach/hackaton/split_dataset/train/images/5 (94).jpg\n",
      "(1, 5)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1695/172709972.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1695/2884136188.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, val_loader, epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1695/1968321881.py\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got numpy.ndarray"
     ]
    }
   ],
   "source": [
    "model, total_train_loss = train(train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afde5cba-714a-48b7-ae86-66c70bb29cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30df9b7f-adf9-497c-9e1c-437abb00cd6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a647db13-9f24-4d23-83a6-f2a740b78d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e40357-5978-4ffd-ba42-40bc3b50ab37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25523b3-729f-4ed2-8220-75d664e5f467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
